## ğŸ“Š GitHub Repos Language ETL

**An ETL pipeline to collect, process, and analyze programming languages used in public repositories from major tech companies on GitHub.**

---

### ğŸš€ What this project does

This project automates the extraction and processing of GitHub repositories for companies such as **Amazon**, **Netflix**, and **Spotify**, generating a clean dataset of repository names and their primary programming languages.

---

### ğŸ§± Project Structure

```

.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw API data (JSON)
â”‚   â””â”€â”€ processed/            # Final CSV files
â”œâ”€â”€ notebooks/                
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ repos_data.py     # Core class for data extraction
â”‚   â”œâ”€â”€ extract.py            # Executes data extraction for each company
â”‚   â”œâ”€â”€ load.py               # Combines and saves final dataset
    â”œâ”€â”€ transform_&_load.ipynb # Notebook for cleaning, merging and exporting language data
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .env                      # API token (not tracked)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

### âš™ï¸ Features

- ğŸ” Loads GitHub API token from `.env`
- ğŸŒ Extracts public repositories for multiple organizations
- ğŸ§¼ Cleans and structures repository name & language
- ğŸ“ Saves per-company CSVs and a combined dataset
- ğŸ“¦ Modular code with `extract`, `transform`, `load` steps

---

### ğŸ“¦ Technologies Used

- `Python 3.10+`
- `Pandas`
- `Requests`
- `dotenv`

---

### ğŸ“ Example Output

**`data/processed/all_companies_languages.csv`**

| repository_name | language | source |
| --- | --- | --- |
| firetv-app | Java | amazon |
| api-gateway | Go | netflix |
| wrapped-2022 | TypeScript | spotify |

---

> ğŸ’¡ This project was developed and tested using WSL2 (Ubuntu 22.04) on Windows.

---

### ğŸ”§ Setup Instructions

```bash

# Clone the repository
git clone https://github.com/your-username/github-repos-language-etl
cd github-repos-language-etl

# Create a virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create a .env file with your GitHub API token
echo "ACCESS_TOKEN=your_github_token_here" > .env

# Run extraction and loading
python -m src.extract
python -m src.load
```

---

### ğŸ“ˆ Next Steps

- Add more companies (Meta, Google, Microsoftâ€¦)
- Visualize the language distribution
- Export to a database or dashboard

---

### ğŸ‘©â€ğŸ’» Developed by

Luiza Vieira â€“ Systems Analysis and Development student - Cesar School

  - ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/vbluuiza)
  - ğŸ’» [GitHub](https://github.com/vbluuiza)
